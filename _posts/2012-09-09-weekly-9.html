---
layout: default
title: 九月份周报 
author: zzh 
---
<p id="fortitle"> {{ site.time | date_to_xmlschema }} </p>

<h4><a href="#">36</a></h4>
<pre class="preclass">
一：本周完成工作
 1.1 对通讯的进行进一步的测试
   1.1.1 由于之前的上下联通还没有全部完成，所作的通讯压力测试数据有所偏差，
         36周对压力测试进行了比较全面的测试。
   1.1.2 经过计算，128DC在混合模式下，每秒的通讯数据为1M左右，
         所以通讯数据交换机压力等在实际场合的性能瓶颈理论上不存在
         在实际的测试中，用一台单独的机器跑作为DC模拟器，另外一台机器跑上位管理
         软件，与模拟DC与管理软件在一台机器上跑的性能基本无区别。
   1.1.3 在V1.2版本的管理软件上TCP通讯采取的是TCPThreadingServer，每个链接启动一个线程，
         在V2，0的版本中，开始也采取了多线程的方式，在混合模式下性能很差，在16模拟DC情况下
         即开始timeout异常，而CPU只占用60%左右，经过查资料和测试，多线程不能充分利用多核处理器
         改为多进程后，性能明显提升，也可以充分的利用多核处理器，模拟DC可以链接到32个。
   1.1.4 在测试多进程和多线程时候，得到下面一组数据
  1：MODE = 3 混合模式，单进程处理时间 ----- 4秒/100次
  2：多线程，改善性能空间很小
  4：多进程下，20DC所用时间与单个DC多用时间差不多
  5：64DC 1000次 最慢0天0小时4分17秒834毫秒 ！0.258/次 
  6：32DC 1000次 最慢0天0小时2分8秒640毫秒  ！0.129/次 
  7：48DC 1000次 最慢0天0小时3分13秒264毫秒 ！0.193/次 
  通过上面数据，理论上多进程可以跑到48DC，实际情况是32DC比较稳定，
  在实验过程中，多线程处理会出现时间的延时，可能是网络传输的数据处理不过来会出现数据缓存
  
        说明：以上数据是在无通讯环境下进行的，数据是通过都文件的方式放如全局变量中，
             测试时间基本为数据接受后，处理的数据所用的时间

   1.1.5 通过上述数据分析，性能的优化空间有两种，
            1； 通讯方式 现在的多进程和多线程都没有满足足够的DC容量，加入其他的方式或是混合一些方式也许是
                解决的办法
            2： 改善占用时间的代码 经过profile的测试，保存wav日志，占用时间的10%左右，
                unpack占用10% 左右，后台的一些数据库操作占用20%左右（当报警时保存报警信息）。
   1.1.6 测试的机器硬软件配置简要：
         处理器：AMD 四核 800MH HZ
         内存：3750M
         系统： deepLinux 内核：3.2.29
   1.1.7 得出的现在的压力通讯数据
         混合模式下，在报警较多的情况下（每个PA每三秒一次报警），可以正常不报错跑32DC
         预处理模式下，可以不报错跑64DC

 1.2 对模拟DC改善，可以为调试提供不过通讯来提供数据数据和专跑DC模拟器的Linux虚拟机
     1.2.1 由于windows机器之前没有提供DC模拟器的支持，现装了一个VBOX的虚拟机，里面专跑DC模拟器
           虚拟机的软件已经装好，启动之后即可配置跑起来模拟DC，并在170的机器上FTP提供VBOX的软件
           和打包虚拟机的下载
     1.2.2 针对调试提供了不通过网络的数据TCP波形数据的提供模拟接口，实现的方式是读取文件，
           提供单个DC的调试
 
 1.3 对通讯部分的代码BUG修改，
     对开发过程中发现的BUG进行修改，增加在UDP通讯中，下位机报错的容错处理。

二、遇到有问题及解决方法：
1. 问题：无
2. 需领导协助：无


三：下周计划
 3.1 继续测试和改进通讯性能
   3.1.1  找出代码中可以改善的地方，比如建立数据库处理的缓存层
   3.1.2  实验其他的通讯方式，比如进程线程混合模式，协程或是寻找一下其他的轻量进程线程实现方法
   3.1.3  深入的研究一下Python的协作模式，和内存缓存机制
 3.2 跟随进度改善代码，UDP部分的log日志部分，TCP部分的log部分（log过多也会影响性能）
 3.3 根据需求，对DC模拟器提供更加方便友好的支持
</pre>
<h4><a href="#">37</a></h4>
<pre class="preclass">
一：本周完成工作
 1 对通讯层进行进一步的完善
   1.1 针对之前的性能问题，找出好的解决办法。测试了greenlet等其他的微线程的实现
        1.1.1 greenlet的实现方式很难实现现在的通讯框架，他的调度有C的goto,需要
                手动调度，经过测试，greenlet相比普通的thread性能有所提升，但是还没有
                找到有效的在项目中使用的方式
        1.1.2 实验了多进程的方式（多进程的方式的性能上周做了验证）在进程间通讯上还存在
                一些问题，需要继续完善改进，看看是否可以在项目中使用。

 2 针对v1.x项目中的bug,提供支持，并在V2.0的代码中有效改善这一部分代码
     2.1 根据何荔等提供的bug报告和问题信息，在V1.x的代码基础上提供了一些意见，
           并且做了部分验证
           2.1.1  根据log分析和实验的现象，我的猜测是：在单一的TCP通是的时候，没有出
                    现报错现象，当通讯方式为混可模式的时候,udp通讯如果出现不正常，
                    timeout的时间内就会导致当前线程无法进行有效的通讯导致中断
     2.2 针对1.x的问题，在v2.0的代码中，加入了udp的通讯检验，减小udp的timeout长度，
           当通讯不正常的时候进行重新链接发送，并提交log日志记录等措施(或可加上把设置不正常的信息报告给前端)。
 
 3上下联通的部分测试。
     对上下联通做了测试，并对view层的代码熟悉了一下，也方便了测试，可以更加准确的看到view与通讯
     数据获取时候正确.

二、遇到有问题及解决方法：
1. 问题：无
2. 需领导协助：无


三：下周计划
 1 继续测试和改进通讯性能
   1.1  多进程实现方式的可行性测试
   1.2  其他通讯方式的可行性测试
 2 跟随进度改善代码，熟悉整个项目的代码，提供测试方法一些想法和做法（压力性能测试和功能测试）
</pre>

<h4><a href="#">38</a></h4>
<pre class="preclass">
一：本周完成工作
 1 对通讯层的压力测试
    1.1 测试环境 硬件：AMD四核800MHZ，2.73G内存。模式：预处理模式 其他环境：数据的报错比较频繁，1次/秒/PA，中间不做0.2秒延时
    1.2 数据：MODE = 1 预处理模式
  	1：1DC 1000 ----- 2.8秒/100次
  	2：4DC 1000次 最慢0天0小时4分17秒834毫秒 ！0.258/次 
	3：8DC 1000次 最慢0天0小时4分17秒834毫秒 ！0.258/次
  	4：16DC 1000次 最慢0天0小时2分8秒640毫秒  ！0.129/次 
  	5：32DC 1000次 最慢0天0小时3分13秒264毫秒 ！0.193/次
	6：32DC 1000次 最慢0天0小时3分13秒264毫秒 ！0.193/次 
   1.3 多进程方式实现
	1：多进程已经找到实现的方式，根据现在DEMO的验证，可以在multiprocessing下用Manager来实现方便的多进程数据共享，现阶段多进程还需要在数据共享，进程间通讯进一步与张天文合作完善。并测试其效率。
 	

 2 PA状态的实时变换
     2.1 对PA状态的变化做了调整，当TCP连接的时候和断开的时候个改变PA的状态，并与数据库同步。
     2.2 当算法得到PA的状态变化时，改变PA的状态，并与数据库同步。

二、遇到有问题及解决方法：
1. 问题：无
2. 需领导协助：无


三：下周计划
 1 继续测试和改进通讯性能
   1.1  在测试评估的基础上得到多线程方式的可用性结论
   1.2  多进程方式的完善，评估，测试
 2 V2.0版本管理软件整体的测试评估，输出下一阶段的工作重点和计划
</pre>
